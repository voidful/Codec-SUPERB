Codec                                    | BPS (kbps) | TPS       
-----------------------------------------------------------------
academicodec_hifi_16k_320d               | ?          | 50.00      (Shape: torch.Size([4, 50]), Layers: 1)
academicodec_hifi_16k_320d_large_uni     | ?          | 50.00      (Shape: torch.Size([4, 50]), Layers: 1)
academicodec_hifi_24k_320d               | ?          | 75.00      (Shape: torch.Size([4, 75]), Layers: 1)
Load tx_encoder: audiodec_autoencoder_24k_320d/checkpoint-500000steps.pkl
Load rx_encoder: audiodec_autoencoder_24k_320d/checkpoint-500000steps.pkl
Load decoder: audiodec_vocoder_24k_320d/checkpoint-500000steps.pkl
audiodec_24k_320d                        | ?          | 80.00      (Shape: torch.Size([8, 80]), Layers: 1)
[AUV] Missing keys in checkpoint (using default values): 60 keys
[AUV] Detected GELU->Snake conversion, initializing Snake alpha parameters...
auv                                      | ?          | 50.00      (Shape: torch.Size([1, 50]), Layers: 1)
bigcodec_1k                              | ?          | 80.00      (Shape: torch.Size([1, 80]), Layers: 1)
dac_16k                                  | ?          | 50.00      (Shape: torch.Size([50, 12]), Layers: 1)
dac_24k                                  | ?          | 75.00      (Shape: torch.Size([75, 32]), Layers: 1)
dac_44k                                  | ?          | 87.00      (Shape: torch.Size([87, 9]), Layers: 1)
encodec_24k_12bps                        | ?          | 75.00      (Shape: torch.Size([16, 75]), Layers: 1)
encodec_24k_1_5bps                       | ?          | 75.00      (Shape: torch.Size([2, 75]), Layers: 1)
encodec_24k_24bps                        | ?          | 75.00      (Shape: torch.Size([32, 75]), Layers: 1)
encodec_24k_3bps                         | ?          | 75.00      (Shape: torch.Size([4, 75]), Layers: 1)
encodec_24k_6bps                         | ?          | 75.00      (Shape: torch.Size([8, 75]), Layers: 1)
funcodec_en_libritts_16k_gr1nq32ds320    | ?          | 51.00      (Shape: torch.Size([32, 51]), Layers: 1)
funcodec_en_libritts_16k_gr8nq32ds320    | ?          | 51.00      (Shape: torch.Size([32, 51]), Layers: 1)
funcodec_en_libritts_16k_nq32ds320       | ?          | 50.00      (Shape: torch.Size([32, 50]), Layers: 1)
funcodec_en_libritts_16k_nq32ds640       | ?          | 32.00      (Shape: torch.Size([32, 25]), Layers: 1)
funcodec_zh_en_16k_nq32ds320             | ?          | 50.00      (Shape: torch.Size([32, 50]), Layers: 1)
funcodec_zh_en_16k_nq32ds640             | ?          | 32.00      (Shape: torch.Size([32, 25]), Layers: 1)
s3tokenizer_v1                           | ?          | 50.00      (Shape: torch.Size([50]), Layers: 1)
speech_tokenizer_16k                     | ?          | 50.00      (Shape: torch.Size([8, 50]), Layers: 1)
sqcodec_16k_0k75bps                      | ?          | 200.00     (Shape: torch.Size([1, 200]), Layers: 1)
sqcodec_16k_12kbps                       | ?          | 800.00     (Shape: torch.Size([1, 800]), Layers: 1)
sqcodec_16k_1k5bps                       | ?          | 300.00     (Shape: torch.Size([1, 300]), Layers: 1)
sqcodec_16k_3kbps                        | ?          | 400.00     (Shape: torch.Size([1, 400]), Layers: 1)
sqcodec_16k_6kbps                        | ?          | 600.00     (Shape: torch.Size([1, 600]), Layers: 1)
sqcodec_24k_12kbps                       | ?          | 800.00     (Shape: torch.Size([1, 800]), Layers: 1)
sqcodec_24k_24kbps                       | ?          | 1800.00    (Shape: torch.Size([1, 1800]), Layers: 1)
making attention of type 'vanilla' with 768 in_channels
unicodec_24k                             | ?          | 75.00      (Shape: torch.Size([1, 75]), Layers: 1)
wavtokenizer_24k_large_600_4096          | ?          | 40.00      (Shape: torch.Size([1, 40]), Layers: 1)
wavtokenizer_24k_large_speech_75token    | ?          | 75.00      (Shape: torch.Size([1, 75]), Layers: 1)
wavtokenizer_24k_medium_600_4096         | ?          | 75.00      (Shape: torch.Size([1, 75]), Layers: 1)
wavtokenizer_24k_small_600_4096          | ?          | 40.00      (Shape: torch.Size([1, 40]), Layers: 1)
